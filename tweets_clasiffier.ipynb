{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweets_clasiffier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXmzRmsYTJ5k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "3a1ddc30-b129-433d-b2c3-5fed847f6fca"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import sys\n",
        "import spacy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext.vocab import Vectors\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "import string \n",
        "\n",
        "train_test_file = '/content/drive/My Drive/studies/nlp/finalProject/gender-classifier-DFE-791531.csv'\n",
        "w2v_file = '/content/drive/My Drive/test_data/glove.840B.300d.txt'\n",
        "data_encoding = \"latin1\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UadXq9MFXJ_O"
      },
      "source": [
        "# **Data Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVwqLDrMVN7s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "outputId": "d7f141dc-49f2-4940-94dd-5507481c0fe6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "# data statictics\n",
        "\n",
        "data_csv = pd.read_csv(train_test_file , encoding = data_encoding)\n",
        "\n",
        "# keep only gender and tweet text\n",
        "data_csv = pd.concat( [ data_csv.gender, data_csv.description, data_csv.text, data_csv.tweet_count ], axis = 1 )\n",
        "\n",
        "# remove unknown gender from data\n",
        "data_csv = data_csv[data_csv.gender != \"unknown\"]\n",
        "\n",
        "\n",
        "fontsize = 15\n",
        "\n",
        "\n",
        "label = ['male', 'female', 'brand']\n",
        "counts = [data_csv.gender.value_counts()[b] for b in label]\n",
        "index = np.arange(len(label))\n",
        "plt.bar(index, counts)\n",
        "plt.xlabel('gender', fontsize=fontsize)\n",
        "plt.ylabel('tweets', fontsize=fontsize)\n",
        "plt.xticks(index, label, fontsize=fontsize)\n",
        "plt.title('gender distribution')\n",
        "plt.show()\n",
        "\n",
        "lenlabel = np.arange(len(label))\n",
        "malecount = data_csv.tweet_count[data_csv.gender == 'male']\n",
        "femalecount = data_csv.tweet_count[data_csv.gender == 'female']\n",
        "brandcount = data_csv.tweet_count[data_csv.gender == 'brand']\n",
        "heights = [ malecount.mean(), femalecount.mean(), brandcount.mean() ]\n",
        "plt.bar(lenlabel, heights )\n",
        "plt.xlabel('gender', fontsize=fontsize)\n",
        "plt.ylabel('average counts', fontsize=fontsize)\n",
        "plt.xticks(lenlabel, label, fontsize=fontsize)\n",
        "plt.title(\"average counts per gender\")\n",
        "plt.show()\n",
        "\n",
        "mins = [ malecount.min(), femalecount.min(), brandcount.min() ]\n",
        "means = [ malecount.mean(), femalecount.mean(), brandcount.mean() ]\n",
        "maxs = [ malecount.max(), femalecount.max(), brandcount.max() ]\n",
        "x = np.arange(len(label))  # the label locations\n",
        "width = 0.2  # the width of the bars\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width, mins, width, label='Min')\n",
        "rects2 = ax.bar(x + width, means, width, label='Avg')\n",
        "rects3 = ax.bar(x, maxs, width, label='Max')\n",
        "ax.set_ylabel('Counts', fontsize=fontsize)\n",
        "ax.set_title('statistic per gender')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(label, fontsize=fontsize)\n",
        "ax.legend()\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEgCAYAAABxQp66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA5l7RgoVllItAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEgCAYAAACNV7VwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVmlnGjMzKxS/x+9XAEdwKN9wwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nheQCZWZmhfT/AeG1l6R0dIHMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6lnGWQiWBQC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aac3e0d4-09b0-4704-9132-e81be1e5aaad"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopword length: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-IOcjTEX2zS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "8855011d-3fe1-4fc0-b216-14bd5368bc72"
      },
      "source": [
        "# had probloms downloading nltk stopwords, so we downloaded them from http://www.nltk.org/nltk_data/ to a file\n",
        "stopwords_file = \"/content/drive/My Drive/studies/nlp/finalProject/nltk_stopwords_english\"\n",
        "with open(stopwords_file, 'r') as sw:\n",
        "  l = sw.read()\n",
        "  stop_words = l.split('\\n')\n",
        "\n",
        "print(\"stopword length: \" + str(len(stop_words))) \n",
        "\n",
        "#loading the data\n",
        "df = pd.read_csv(train_test_file , encoding = data_encoding)\n",
        "headers = list(df.columns.values)\n",
        "\n",
        "targets = {'female', 'male', 'brand'}\n",
        "\n",
        "#Remove rows without classify or empty\n",
        "filtered_df = df.loc[df['gender'].isin(['female', 'male', 'brand'])]\n",
        "\n",
        "target = filtered_df[\"gender\"]\n",
        "filtered_df.loc[df['text'].isnull(),'text'] = \".\"\n",
        "filtered_df.loc[df['description'].isnull(),'description'] = \".\"\n",
        "\n",
        "tweets = filtered_df[\"text\"].map(str) + \" \"+ filtered_df[\"description\"]\n",
        "\n",
        "df[\"gender\"].value_counts()\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "stop_words = list(stop_words) + list(string.punctuation) + list('__')\n",
        " \n",
        "emoticons_str = r\"\"\"\n",
        "    (?:\n",
        "        [:=;] # Eyes\n",
        "        [oO\\-]? # Nose (optional)\n",
        "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
        "    )\"\"\"\n",
        " \n",
        "regex_str = [\n",
        "    emoticons_str,\n",
        "    r'<[^>]+>', # HTML tags\n",
        "    r'(?:@[\\w_]+)', # @-mentions\n",
        "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
        "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
        "    r'(?:[\\w_]+)', # other words\n",
        "    r'(?:\\S)' # anything else\n",
        "]\n",
        "    \n",
        "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
        "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
        " \n",
        "  \n",
        "def tokenize(tweet, lowercase=False):\n",
        "    tokens_without_SW = []\n",
        "    tweet = re.sub(r'[^\\x00-\\x7f]*',r'',tweet) \n",
        "    tokens = tokens_re.findall(tweet)\n",
        "    if lowercase:\n",
        "        tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
        "        \n",
        "    for token in tokens:\n",
        "        if token not in stop_words:\n",
        "            tokens_without_SW.append(token)\n",
        "    return tokens_without_SW\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "#Create 3 arrays, 1 for every target\n",
        "female = df.loc[df['gender']== 'female']['text']\n",
        "male = df.loc[df['gender']== 'male']['text']\n",
        "brand = df.loc[df['gender']== 'brand']['text']\n",
        "\n",
        "def getMostCommonWords(tweets_array):\n",
        "    res = []\n",
        "    c = Counter()\n",
        "    for tweet in tweets_array:\n",
        "        for token in tokenize(tweet, True):\n",
        "            res.append(token)\n",
        "    c.update(res)\n",
        "    return c.most_common(10)\n",
        "\n",
        "print(\"Top 10 words in Female target:\\n\")\n",
        "print(getMostCommonWords(female))\n",
        "print(\"\\nTop 10 words in Male target:\\n\")\n",
        "print(getMostCommonWords(male))\n",
        "print(\"\\nTop 10 words in Brand target:\\n\")\n",
        "print(getMostCommonWords(brand))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopword length: 180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Top 10 words in Female target:\n",
            "\n",
            "[('like', 451), ('get', 353), ('__', 333), ('one', 332), ('love', 315), ('day', 296), ('go', 278), ('people', 249), ('time', 241), ('know', 210)]\n",
            "\n",
            "Top 10 words in Male target:\n",
            "\n",
            "[('like', 352), ('get', 346), ('one', 267), ('time', 232), ('new', 216), ('love', 210), ('go', 205), ('people', 197), ('good', 186), ('day', 186)]\n",
            "\n",
            "Top 10 words in Brand target:\n",
            "\n",
            "[('weather', 2279), ('get', 1326), ('channel', 1169), ('15', 1166), ('updates', 1147), ('40', 727), ('39', 424), ('new', 244), ('amp', 191), ('us', 167)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY-a6YhEXv0v"
      },
      "source": [
        "# **running the models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWasPIchdQr4"
      },
      "source": [
        "from enum import Enum\n",
        "\n",
        "class DatasetEnum(Enum):\n",
        "        GenderText = 1\n",
        "        GenderTextDescription = 2\n",
        "        GenderTextDescriptionTweetCount = 3\n",
        "        GenderTextTweetCount = 4\n",
        "        \n",
        "def get_datafields(dataset_type, tokenizer):\n",
        "        TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True)\n",
        "        LABEL = data.Field(sequential=False, use_vocab=False)\n",
        "        DESCRIPTION = data.Field(sequential=True, tokenize=tokenizer, lower=True)\n",
        "        TWEET_COUNT = data.Field(sequential=False, use_vocab=False)\n",
        "        \n",
        "        if dataset_type == DatasetEnum.GenderText:     \n",
        "            datafields = [(\"label\",LABEL), (\"text\",TEXT)]          \n",
        "        elif dataset_type == DatasetEnum.GenderTextDescription:     \n",
        "            datafields = [(\"label\",LABEL), (\"description\", DESCRIPTION), (\"text\",TEXT)]\n",
        "        elif dataset_type == DatasetEnum.GenderTextDescriptionTweetCount:     \n",
        "            datafields = [(\"label\",LABEL), (\"description\", DESCRIPTION), (\"text\",TEXT), (\"tweet_count\", TWEET_COUNT)]\n",
        "        elif dataset_type == DatasetEnum.GenderTextTweetCount:     \n",
        "            datafields = [(\"label\",LABEL), (\"text\",TEXT), (\"tweet_count\", TWEET_COUNT)]\n",
        "            \n",
        "        return datafields, TEXT, LABEL, DESCRIPTION, TWEET_COUNT                 \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5bDu-kqYFgF"
      },
      "source": [
        "### Configurations\n",
        "We used two types of configurations for data processing:\n",
        "1. **text_process_args_vars**:\n",
        "   determains the type of processing we are doing on the text fields -   \n",
        "   i. keep_letters_only - removes all chars that are not english letters  \n",
        "   ii. lemmatize  \n",
        "   iii. remove_stopwords  \n",
        "   iv. to_lower_case (we ended up running to_lower_case = True everytime)\n",
        "   \n",
        "2. **dataset_configs**:\n",
        "   This configuration refers to what fields to keep from the dataset.  \n",
        "   Gender and Text (tweet) are always used.  \n",
        "   Description and Tweet Count are not always used.\n",
        "   \n",
        "\n",
        "**DEBUG flag** - \n",
        "this flag refers to debug logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jths5q0YEq7"
      },
      "source": [
        "text_process_args_vars = [\n",
        "    {\"keep_letters_only\": True, \"to_lower_case\": True, \"lemmatize\": True, \"remove_stopwords\": True},\n",
        "    {\"keep_letters_only\": True, \"to_lower_case\": True, \"lemmatize\": True, \"remove_stopwords\": False},\n",
        "    {\"keep_letters_only\": True, \"to_lower_case\": True, \"lemmatize\": False, \"remove_stopwords\": True}, \n",
        "    {\"keep_letters_only\": True, \"to_lower_case\": True, \"lemmatize\": False, \"remove_stopwords\": False},\n",
        "    {\"keep_letters_only\": False, \"to_lower_case\": True, \"lemmatize\": True, \"remove_stopwords\": True},\n",
        "    {\"keep_letters_only\": False, \"to_lower_case\": True, \"lemmatize\": True, \"remove_stopwords\": False},\n",
        "    {\"keep_letters_only\": False, \"to_lower_case\": True, \"lemmatize\": False, \"remove_stopwords\": True},\n",
        "    {\"keep_letters_only\": False, \"to_lower_case\": True, \"lemmatize\": False, \"remove_stopwords\": False}]\n",
        "\n",
        "dataset_configs = [\n",
        "    {\"dataset_type\" : DatasetEnum.GenderText, \"remove_brand\" : True },\n",
        "    {\"dataset_type\" : DatasetEnum.GenderText, \"remove_brand\" : False },\n",
        "    {\"dataset_type\" : DatasetEnum.GenderTextDescription, \"remove_brand\" : True },\n",
        "    {\"dataset_type\" : DatasetEnum.GenderTextDescription, \"remove_brand\" : False },\n",
        "    {\"dataset_type\" : DatasetEnum.GenderTextTweetCount, \"remove_brand\" : True },\n",
        "    {\"dataset_type\" : DatasetEnum.GenderTextTweetCount, \"remove_brand\" : False },\n",
        "    {\"dataset_type\" : DatasetEnum.GenderTextDescriptionTweetCount, \"remove_brand\" : True },\n",
        "    {\"dataset_type\" : DatasetEnum.GenderTextDescriptionTweetCount, \"remove_brand\" : False }\n",
        "]\n",
        "\n",
        "DEBUG = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4CMDxwPdl0O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "65d1de68-695a-494f-8526-8e5869f2cdba"
      },
      "source": [
        "# had probloms downloading nltk stopwords, so we downloaded them from http://www.nltk.org/nltk_data/ to a file\n",
        "stopwords_file = \"/content/drive/My Drive/studies/nlp/finalProject/nltk_stopwords_english\"\n",
        "with open(stopwords_file, 'r') as sw:\n",
        "  l = sw.read()\n",
        "  stop_words = l.split('\\n')\n",
        "\n",
        "print(\"stopword length: \" + str(len(stop_words)))  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopword length: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VQQedA2blw9"
      },
      "source": [
        "# UTILS\n",
        "def gender_int_value(gender):\n",
        "    if gender == \"female\":\n",
        "        return \"1\"\n",
        "    elif gender == \"male\":\n",
        "        return \"2\"\n",
        "    elif gender == \"brand\":\n",
        "        return \"3\"\n",
        "    else:\n",
        "        return \"4\"\n",
        "\n",
        "def process_tweet(text, keep_letters_only=False, to_lower_case=False, lemmatize=False, remove_stopwords=False):\n",
        "      if text == \"\" or not text:        \n",
        "        text = \"empty\"\n",
        "      lemma = nltk.WordNetLemmatizer()\n",
        "\n",
        "      if keep_letters_only:       \n",
        "        text = re.sub( \"[^a-zA-z]\", \" \", text)\n",
        "      if to_lower_case:       \n",
        "        text = text.lower()\n",
        "\n",
        "\n",
        "      text = nltk.word_tokenize(text)\n",
        "\n",
        "      if lemmatize:        \n",
        "        text = [ lemma.lemmatize(word) for word in text ]\n",
        "      if remove_stopwords:        \n",
        "        # had probloms downloading nltk stopwords, so we downloaded them from http://www.nltk.org/nltk_data/ to a file\n",
        "        stopwords_file = \"/content/drive/My Drive/studies/nlp/finalProject/nltk_stopwords_english\"\n",
        "\n",
        "        with open(stopwords_file, 'r') as sw:\n",
        "          l = sw.read()\n",
        "          stopwords = l.split('\\n')\n",
        "        \n",
        "        # adding punctuation to the stopwords list\n",
        "        stopwords = list(stop_words) + list(string.punctuation)\n",
        "        text = [word for word in text if word not in stopwords]\n",
        "\n",
        "      text = \" \".join(text)\n",
        "      return text\n",
        "\n",
        "\n",
        "def evaluate_model(model, iterator):\n",
        "    all_preds = []\n",
        "    all_y = []\n",
        "    for idx,batch in enumerate(iterator):\n",
        "        if torch.cuda.is_available():\n",
        "            x = batch.text.cuda()\n",
        "        else:\n",
        "            x = batch.text\n",
        "        y_pred = model(x)\n",
        "        predicted = torch.max(y_pred.cpu().data, 1)[1] + 1\n",
        "        all_preds.extend(predicted.numpy())\n",
        "        all_y.extend(batch.label.numpy())\n",
        "    score = accuracy_score(all_y, np.array(all_preds).flatten())\n",
        "    return score\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5h8vFXlWMmT"
      },
      "source": [
        "def get_train_test_df(filename, dataset_type, text_process_args, remove_brand=False):\n",
        "    data_csv = pd.read_csv(filename, encoding=\"latin\")\n",
        "    \n",
        "    # remove all rows that have \"unknown\" gender\n",
        "    data_csv = data_csv[data_csv.gender != \"unknown\"]\n",
        "    \n",
        "    if remove_brand:\n",
        "          data_csv = data_csv[data_csv.gender != \"brand\"]\n",
        "    \n",
        "    data_csv.gender = [ gender_int_value(currentGender) for currentGender in data_csv.gender ]\n",
        "\n",
        "    \n",
        "    \n",
        "    data_csv.text = [ process_tweet(currentText, **text_process_args) for currentText in data_csv.text ]\n",
        "    \n",
        "    data_csv.description = [ process_tweet(str(currentDesc), **text_process_args) for currentDesc in data_csv.description ]\n",
        "      \n",
        "    data_csv.dropna( subset=[\"gender\", \"text\", \"description\", \"tweet_count\"], inplace = True )\n",
        "    \n",
        "    if dataset_type == DatasetEnum.GenderText:     \n",
        "        data_csv = pd.concat( [ data_csv.gender, data_csv.text], axis = 1 )\n",
        "        data_csv.columns = ['label', 'text']  \n",
        "    elif dataset_type == DatasetEnum.GenderTextDescription:     \n",
        "        data_csv = pd.concat( [ data_csv.gender, data_csv.description, data_csv.text], axis = 1 )\n",
        "        data_csv.columns = ['label', 'description', 'text']  \n",
        "    elif dataset_type == DatasetEnum.GenderTextDescriptionTweetCount:     \n",
        "        data_csv = pd.concat( [ data_csv.gender, data_csv.description, data_csv.text, data_csv.tweet_count], axis = 1 )\n",
        "        data_csv.columns = ['label', 'description', 'text', 'tweet_count']  \n",
        "    elif dataset_type == DatasetEnum.GenderTextTweetCount:     \n",
        "        data_csv = pd.concat( [ data_csv.gender, data_csv.text, data_csv.tweet_count], axis = 1 )\n",
        "        data_csv.columns = ['label', 'text', 'tweet_count']  \n",
        "\n",
        "    msk = np.random.rand(len(data_csv)) < 0.8\n",
        "\n",
        "    train = data_csv[msk]\n",
        "    test = data_csv[~msk]\n",
        "\n",
        "    print(\"done loading data\")\n",
        "    return train, test\n",
        "\n",
        "def get_train_test_val(train_test_file, datafields, dataset_type, text_process_args, remove_brand=False):\n",
        "    train_df, test_df = get_train_test_df(train_test_file, dataset_type, text_process_args, remove_brand)        \n",
        "  \n",
        "    train_examples = [data.Example.fromlist(i, datafields) for i in train_df.values.tolist()]\n",
        "    train_data = data.Dataset(train_examples, datafields)\n",
        "\n",
        "    test_examples = [data.Example.fromlist(i, datafields) for i in test_df.values.tolist()]\n",
        "    test_data = data.Dataset(test_examples, datafields)\n",
        "\n",
        "    train_data, val_data = train_data.split(split_ratio=0.8)\n",
        "\n",
        "    return train_data, test_data, val_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0G6LANaKQ1O"
      },
      "source": [
        "\n",
        "\n",
        "def train_and_eval(model, config, dataset):\n",
        "  if torch.cuda.is_available():\n",
        "      model.cuda()\n",
        "  model.train()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=config.lr)\n",
        "  NLLLoss = nn.NLLLoss()\n",
        "  model.add_optimizer(optimizer)\n",
        "  model.add_loss_op(NLLLoss)\n",
        "\n",
        "\n",
        "  train_losses = []\n",
        "  val_accuracies = []\n",
        "\n",
        "  for i in range(config.max_epochs):\n",
        "      if DEBUG:\n",
        "        print (\"Epoch: {}\".format(i))\n",
        "      train_loss,val_accuracy = model.run_epoch(dataset.train_iterator, dataset.val_iterator, i)\n",
        "      train_losses.append(train_loss)\n",
        "      val_accuracies.append(val_accuracy)\n",
        "\n",
        "  train_acc = evaluate_model(model, dataset.train_iterator)\n",
        "  val_acc = evaluate_model(model, dataset.val_iterator)\n",
        "  test_acc = evaluate_model(model, dataset.test_iterator)\n",
        "\n",
        "  print ('Final Training Accuracy: {:.4f}'.format(train_acc))\n",
        "  print ('Final Validation Accuracy: {:.4f}'.format(val_acc))\n",
        "  print ('Final Test Accuracy: {:.4f}'.format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPUQWYGeyYqV"
      },
      "source": [
        "## Fast Text Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q8z0m_8puxh"
      },
      "source": [
        "####### FastText MODEL #####\n",
        "\n",
        "class FastTextConfig(object):\n",
        "    embed_size = 300\n",
        "    hidden_size = 10\n",
        "    output_size = 4\n",
        "    max_epochs = 30\n",
        "    lr = 0.5\n",
        "    batch_size = 128\n",
        "    \n",
        "class FastTextDataset(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.train_iterator = None\n",
        "        self.test_iterator = None\n",
        "        self.val_iterator = None\n",
        "        self.vocab = []\n",
        "        self.word_embeddings = {}\n",
        "    \n",
        "\n",
        "    def load_data(self, w2v_file, train_test_file, dataset_config, text_process_args):\n",
        "        description = False        \n",
        "        \n",
        "        NLP = spacy.load('en')\n",
        "        tokenizer = lambda sent: [x.text for x in NLP.tokenizer(sent) if x.text != \" \"]\n",
        "        \n",
        "        datafields, TEXT, LABEL, DESCRIPTION, TWEET_COUNT = get_datafields(dataset_config[\"dataset_type\"], tokenizer)    \n",
        "        train_data, test_data, val_data = get_train_test_val(train_test_file, datafields, dataset_config[\"dataset_type\"], text_process_args, remove_brand = dataset_config[\"remove_brand\"])\n",
        "        \n",
        "        \n",
        "        print(\"building vocab\")\n",
        "        TEXT.build_vocab(train_data, vectors=Vectors(w2v_file))\n",
        "        \n",
        "        if dataset_config[\"dataset_type\"] == DatasetEnum.GenderTextDescription or dataset_config[\"dataset_type\"] == DatasetEnum.GenderTextDescriptionTweetCount:\n",
        "          DESCRIPTION.vocab = TEXT.vocab\n",
        "        \n",
        "        \n",
        "        self.word_embeddings = TEXT.vocab.vectors        \n",
        "        self.vocab = TEXT.vocab\n",
        "        \n",
        "        \n",
        "        self.train_iterator = data.BucketIterator(\n",
        "            (train_data),\n",
        "            batch_size=self.config.batch_size,\n",
        "            sort_key=lambda x: len(x.text),\n",
        "            repeat=False,\n",
        "            shuffle=True)\n",
        "        \n",
        "        self.val_iterator, self.test_iterator = data.BucketIterator.splits(\n",
        "            (val_data, test_data),\n",
        "            batch_size=self.config.batch_size,\n",
        "            sort_key=lambda x: len(x.text),\n",
        "            repeat=False,\n",
        "            shuffle=False)\n",
        "        \n",
        "        print (\"Loaded {} training examples\".format(len(train_data)))\n",
        "        print (\"Loaded {} test examples\".format(len(test_data)))\n",
        "        print (\"Loaded {} validation examples\".format(len(val_data)))\n",
        "        \n",
        "class fastText(nn.Module):\n",
        "    def __init__(self, config, vocab_size, word_embeddings):\n",
        "        super(fastText, self).__init__()\n",
        "        self.config = config\n",
        "        \n",
        "        # Embedding Layer\n",
        "        self.embeddings = nn.Embedding(vocab_size, self.config.embed_size)\n",
        "        self.embeddings.weight = nn.Parameter(word_embeddings, requires_grad=False)\n",
        "        \n",
        "        # Hidden Layer\n",
        "        self.fc1 = nn.Linear(self.config.embed_size, self.config.hidden_size)\n",
        "        \n",
        "        # Output Layer\n",
        "        self.fc2 = nn.Linear(self.config.hidden_size, self.config.output_size)\n",
        "        \n",
        "        # Softmax non-linearity\n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        embedded_sent = self.embeddings(x).permute(1,0,2)\n",
        "        h = self.fc1(embedded_sent.mean(1))\n",
        "        z = self.fc2(h)\n",
        "        return self.softmax(z)\n",
        "    \n",
        "    def add_optimizer(self, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "    def add_loss_op(self, loss_op):\n",
        "        self.loss_op = loss_op\n",
        "    \n",
        "    def reduce_lr(self):\n",
        "        print(\"Reducing LR\")\n",
        "        for g in self.optimizer.param_groups:\n",
        "            g['lr'] = g['lr'] / 2\n",
        "                \n",
        "    def run_epoch(self, train_iterator, val_iterator, epoch):        \n",
        "        train_losses = []\n",
        "        val_accuracies = []\n",
        "        losses = []\n",
        "        \n",
        "        # Reduce learning rate as number of epochs increase\n",
        "        if (epoch == int(self.config.max_epochs/3)) or (epoch == int(2*self.config.max_epochs/3)):\n",
        "            self.reduce_lr()\n",
        "                 \n",
        "        for i, batch in enumerate(train_iterator):\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            if torch.cuda.is_available():            \n",
        "                x = batch.text.cuda()\n",
        "                y = (batch.label - 1).type(torch.cuda.LongTensor)\n",
        "            else:               \n",
        "                x = batch.text\n",
        "                y = (batch.label - 1).type(torch.LongTensor)\n",
        "\n",
        "            y_pred = self.__call__(x)\n",
        "            loss = self.loss_op(y_pred, y)\n",
        "            loss.backward()\n",
        "            losses.append(loss.data.cpu().numpy())\n",
        "            \n",
        "            self.optimizer.step()\n",
        "    \n",
        "            \n",
        "            if i % 100 == 0:\n",
        "                if DEBUG:\n",
        "                  print(\"Iter: {}\".format(i+1))\n",
        "                avg_train_loss = np.mean(losses)\n",
        "                train_losses.append(avg_train_loss)\n",
        "                \n",
        "                if DEBUG:\n",
        "                  print(\"\\tAverage training loss: {:.5f}\".format(avg_train_loss))\n",
        "                losses = []\n",
        "                \n",
        "                # Evalute Accuracy on validation set\n",
        "                val_accuracy = evaluate_model(self, val_iterator)\n",
        "                if DEBUG:\n",
        "                  print(\"\\tVal Accuracy: {:.4f}\".format(val_accuracy))\n",
        "                self.train()\n",
        "                \n",
        "        return train_losses, val_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22JtWUPmypzL"
      },
      "source": [
        "### Running the Fast Text Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrNOtT-uMUBN"
      },
      "source": [
        "##### FastText ######\n",
        "def run_fast_text(config, dataset_config, text_process_args):\n",
        "  print(\"################\")\n",
        "  print(text_process_args)\n",
        "  print(\"################\")\n",
        "  dataset = FastTextDataset(config)\n",
        "  dataset.load_data(w2v_file, train_test_file, dataset_config, text_process_args)\n",
        "  model = fastText(config, len(dataset.vocab), dataset.word_embeddings)\n",
        "  train_and_eval(model, config, dataset)\n",
        "  \n",
        "fast_text_config = FastTextConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Aru3LoNqHtN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a8e4fc2-d77f-44b5-9bda-2ccdfd2c0145"
      },
      "source": [
        "\n",
        "##### FastText TRAIN ######\n",
        "dataset_config = {\"dataset_type\" : DatasetEnum.GenderText, \"remove_brand\" : True }\n",
        "\n",
        "print(\"#### Gender and Text , REMOVE Brand\")\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_fast_text(fast_text_config, dataset_config, text_process_args)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#### Gender and Text , REMOVE Brand\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8378 training examples\n",
            "Loaded 2518 test examples\n",
            "Loaded 2095 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5135\n",
            "Final Validation Accuracy: 0.5126\n",
            "Final Test Accuracy: 0.5254\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8286 training examples\n",
            "Loaded 2634 test examples\n",
            "Loaded 2071 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5115\n",
            "Final Validation Accuracy: 0.5109\n",
            "Final Test Accuracy: 0.5330\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8331 training examples\n",
            "Loaded 2577 test examples\n",
            "Loaded 2083 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5207\n",
            "Final Validation Accuracy: 0.4950\n",
            "Final Test Accuracy: 0.5157\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8322 training examples\n",
            "Loaded 2589 test examples\n",
            "Loaded 2080 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5198\n",
            "Final Validation Accuracy: 0.5101\n",
            "Final Test Accuracy: 0.5056\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8334 training examples\n",
            "Loaded 2573 test examples\n",
            "Loaded 2084 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5096\n",
            "Final Validation Accuracy: 0.5221\n",
            "Final Test Accuracy: 0.5301\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8277 training examples\n",
            "Loaded 2645 test examples\n",
            "Loaded 2069 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5172\n",
            "Final Validation Accuracy: 0.5012\n",
            "Final Test Accuracy: 0.5225\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8326 training examples\n",
            "Loaded 2583 test examples\n",
            "Loaded 2082 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5160\n",
            "Final Validation Accuracy: 0.5173\n",
            "Final Test Accuracy: 0.5137\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8382 training examples\n",
            "Loaded 2513 test examples\n",
            "Loaded 2096 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5122\n",
            "Final Validation Accuracy: 0.5386\n",
            "Final Test Accuracy: 0.5082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byY9EfhbdipP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06109098-4a02-4647-f0a8-ce7639c74bc5"
      },
      "source": [
        "##### FastText TRAIN ######\n",
        "print(\" FAST TEXT \")\n",
        "print(\"################# Gender and Text, KEEP brand ################\") \n",
        "dataset_config = {\"dataset_type\" : DatasetEnum.GenderText, \"remove_brand\" : False }\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_fast_text(fast_text_config, dataset_config, text_process_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############### FastText #############\n",
            "################# Gender and Text, KEEP brand ################\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12109 training examples\n",
            "Loaded 3797 test examples\n",
            "Loaded 3027 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5178\n",
            "Final Validation Accuracy: 0.4879\n",
            "Final Test Accuracy: 0.4938\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12081 training examples\n",
            "Loaded 3832 test examples\n",
            "Loaded 3020 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5218\n",
            "Final Validation Accuracy: 0.5040\n",
            "Final Test Accuracy: 0.5057\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12171 training examples\n",
            "Loaded 3719 test examples\n",
            "Loaded 3043 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5245\n",
            "Final Validation Accuracy: 0.5021\n",
            "Final Test Accuracy: 0.4816\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12109 training examples\n",
            "Loaded 3797 test examples\n",
            "Loaded 3027 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5255\n",
            "Final Validation Accuracy: 0.5028\n",
            "Final Test Accuracy: 0.5007\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12111 training examples\n",
            "Loaded 3794 test examples\n",
            "Loaded 3028 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5200\n",
            "Final Validation Accuracy: 0.5040\n",
            "Final Test Accuracy: 0.4810\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12041 training examples\n",
            "Loaded 3882 test examples\n",
            "Loaded 3010 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5190\n",
            "Final Validation Accuracy: 0.5365\n",
            "Final Test Accuracy: 0.4979\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12062 training examples\n",
            "Loaded 3856 test examples\n",
            "Loaded 3015 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5211\n",
            "Final Validation Accuracy: 0.5002\n",
            "Final Test Accuracy: 0.4816\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12206 training examples\n",
            "Loaded 3675 test examples\n",
            "Loaded 3052 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5261\n",
            "Final Validation Accuracy: 0.5079\n",
            "Final Test Accuracy: 0.4963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47_IRS-7A_nk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "15f375e2-cdf4-4ada-cb6e-7b5062b11386"
      },
      "source": [
        "##### FastText TRAIN ######\n",
        "print(\"###################### FastText #####################\")\n",
        "print(\"##############Gender Text and Description, REMOVE brand #############\")\n",
        "dataset_config = {\"dataset_type\" : DatasetEnum.GenderTextDescription, \"remove_brand\" : True }\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_fast_text(fast_text_config, dataset_config, text_process_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###################### FastText #####################\n",
            "##############Gender Text and Description, REMOVE brand #############\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8299 training examples\n",
            "Loaded 2617 test examples\n",
            "Loaded 2075 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5192\n",
            "Final Validation Accuracy: 0.5075\n",
            "Final Test Accuracy: 0.5094\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8343 training examples\n",
            "Loaded 2562 test examples\n",
            "Loaded 2086 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5162\n",
            "Final Validation Accuracy: 0.5235\n",
            "Final Test Accuracy: 0.5078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V70XeBs5dzdP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17bd1ac2-2f3d-4ce8-aca8-59fd865cbcbc"
      },
      "source": [
        "##### FastText TRAIN ######\n",
        "print(\"###################### FastText #####################\")\n",
        "print(\"##############Gender Text and Description, REMOVE brand #############\")\n",
        "dataset_config = {\"dataset_type\" : DatasetEnum.GenderTextDescription, \"remove_brand\" : True }\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_fast_text(fast_text_config, dataset_config, text_process_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###################### FastText #####################\n",
            "##############Gender Text and Description, REMOVE brand #############\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8262 training examples\n",
            "Loaded 2664 test examples\n",
            "Loaded 2065 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.6270\n",
            "Final Validation Accuracy: 0.5826\n",
            "Final Test Accuracy: 0.5901\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8341 training examples\n",
            "Loaded 2565 test examples\n",
            "Loaded 2085 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5138\n",
            "Final Validation Accuracy: 0.5372\n",
            "Final Test Accuracy: 0.5045\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8286 training examples\n",
            "Loaded 2633 test examples\n",
            "Loaded 2072 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5138\n",
            "Final Validation Accuracy: 0.5130\n",
            "Final Test Accuracy: 0.5234\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8275 training examples\n",
            "Loaded 2647 test examples\n",
            "Loaded 2069 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5121\n",
            "Final Validation Accuracy: 0.5201\n",
            "Final Test Accuracy: 0.5236\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8303 training examples\n",
            "Loaded 2612 test examples\n",
            "Loaded 2076 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5179\n",
            "Final Validation Accuracy: 0.5183\n",
            "Final Test Accuracy: 0.5065\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8272 training examples\n",
            "Loaded 2651 test examples\n",
            "Loaded 2068 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5115\n",
            "Final Validation Accuracy: 0.5324\n",
            "Final Test Accuracy: 0.5160\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8332 training examples\n",
            "Loaded 2576 test examples\n",
            "Loaded 2083 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5168\n",
            "Final Validation Accuracy: 0.5012\n",
            "Final Test Accuracy: 0.5233\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8329 training examples\n",
            "Loaded 2580 test examples\n",
            "Loaded 2082 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5124\n",
            "Final Validation Accuracy: 0.5259\n",
            "Final Test Accuracy: 0.5182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1RjjkD1fLqZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9daac7cf-f5d0-46c1-f27a-8f43c4b62e17"
      },
      "source": [
        "##### FastText TRAIN ######\n",
        "print(\"############ FastText ################\")\n",
        "print(\"################ Gender Text and Description, KEEP Brand ############\")\n",
        "dataset_config = {\"dataset_type\" : DatasetEnum.GenderTextDescription, \"remove_brand\" : False }\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_fast_text(fast_text_config, dataset_config, text_process_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############ FastText ################\n",
            "################ Gender Text and Description, KEEP Brand ############\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12139 training examples\n",
            "Loaded 3759 test examples\n",
            "Loaded 3035 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5185\n",
            "Final Validation Accuracy: 0.5031\n",
            "Final Test Accuracy: 0.4802\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12093 training examples\n",
            "Loaded 3817 test examples\n",
            "Loaded 3023 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5255\n",
            "Final Validation Accuracy: 0.4969\n",
            "Final Test Accuracy: 0.4965\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12106 training examples\n",
            "Loaded 3800 test examples\n",
            "Loaded 3027 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5145\n",
            "Final Validation Accuracy: 0.5061\n",
            "Final Test Accuracy: 0.4684\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12170 training examples\n",
            "Loaded 3721 test examples\n",
            "Loaded 3042 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5228\n",
            "Final Validation Accuracy: 0.5148\n",
            "Final Test Accuracy: 0.4945\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12149 training examples\n",
            "Loaded 3747 test examples\n",
            "Loaded 3037 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5186\n",
            "Final Validation Accuracy: 0.5123\n",
            "Final Test Accuracy: 0.4804\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12130 training examples\n",
            "Loaded 3771 test examples\n",
            "Loaded 3032 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5218\n",
            "Final Validation Accuracy: 0.5089\n",
            "Final Test Accuracy: 0.4970\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12114 training examples\n",
            "Loaded 3791 test examples\n",
            "Loaded 3028 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5234\n",
            "Final Validation Accuracy: 0.5139\n",
            "Final Test Accuracy: 0.4677\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12125 training examples\n",
            "Loaded 3777 test examples\n",
            "Loaded 3031 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5267\n",
            "Final Validation Accuracy: 0.5216\n",
            "Final Test Accuracy: 0.4935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn5F-Gcgf3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28ef7c11-cabe-46c8-c2ff-b6a9f23c8a0a"
      },
      "source": [
        "##### FastText TRAIN ######\n",
        "print(\"############ Fast Text ###############\")\n",
        "print(\"################# Gender Text Description and TweetCount, REMOVE Brand #######\")\n",
        "dataset_config = {\"dataset_type\" : DatasetEnum.GenderTextDescriptionTweetCount, \"remove_brand\" : True }\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_fast_text(fast_text_config, dataset_config, text_process_args)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############ Fast Text ###############\n",
            "################# Gender Text Description and TweetCount, REMOVE Brand #######\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8318 training examples\n",
            "Loaded 2593 test examples\n",
            "Loaded 2080 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5180\n",
            "Final Validation Accuracy: 0.5082\n",
            "Final Test Accuracy: 0.5145\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8267 training examples\n",
            "Loaded 2657 test examples\n",
            "Loaded 2067 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5146\n",
            "Final Validation Accuracy: 0.5206\n",
            "Final Test Accuracy: 0.5156\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8311 training examples\n",
            "Loaded 2602 test examples\n",
            "Loaded 2078 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5144\n",
            "Final Validation Accuracy: 0.5438\n",
            "Final Test Accuracy: 0.4981\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8290 training examples\n",
            "Loaded 2629 test examples\n",
            "Loaded 2072 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5144\n",
            "Final Validation Accuracy: 0.5072\n",
            "Final Test Accuracy: 0.5268\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8338 training examples\n",
            "Loaded 2568 test examples\n",
            "Loaded 2085 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5155\n",
            "Final Validation Accuracy: 0.5127\n",
            "Final Test Accuracy: 0.5187\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8281 training examples\n",
            "Loaded 2640 test examples\n",
            "Loaded 2070 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5183\n",
            "Final Validation Accuracy: 0.5005\n",
            "Final Test Accuracy: 0.5197\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8303 training examples\n",
            "Loaded 2612 test examples\n",
            "Loaded 2076 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5179\n",
            "Final Validation Accuracy: 0.5087\n",
            "Final Test Accuracy: 0.5134\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8358 training examples\n",
            "Loaded 2543 test examples\n",
            "Loaded 2090 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5129\n",
            "Final Validation Accuracy: 0.5316\n",
            "Final Test Accuracy: 0.5120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoEOkixRaoaS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e8e02b8-60d9-47a7-db40-9355f45313e1"
      },
      "source": [
        "print(\"################## Fast Text ####################\")\n",
        "print(\"############### Gender Text Desciption and Tweet Count, KEEP Brand ############\")\n",
        "dataset_config = {\"dataset_type\" : DatasetEnum.GenderTextDescriptionTweetCount, \"remove_brand\" : False }\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_fast_text(fast_text_config, dataset_config, text_process_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "################## Fast Text ####################\n",
            "############### Gender Text Desciption and Tweet Count, KEEP Brand ############\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12136 training examples\n",
            "Loaded 3763 test examples\n",
            "Loaded 3034 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5171\n",
            "Final Validation Accuracy: 0.5016\n",
            "Final Test Accuracy: 0.4953\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12116 training examples\n",
            "Loaded 3788 test examples\n",
            "Loaded 3029 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5203\n",
            "Final Validation Accuracy: 0.5091\n",
            "Final Test Accuracy: 0.4976\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12094 training examples\n",
            "Loaded 3815 test examples\n",
            "Loaded 3024 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5179\n",
            "Final Validation Accuracy: 0.5099\n",
            "Final Test Accuracy: 0.4826\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12152 training examples\n",
            "Loaded 3743 test examples\n",
            "Loaded 3038 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5197\n",
            "Final Validation Accuracy: 0.5122\n",
            "Final Test Accuracy: 0.5106\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12144 training examples\n",
            "Loaded 3753 test examples\n",
            "Loaded 3036 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5188\n",
            "Final Validation Accuracy: 0.5079\n",
            "Final Test Accuracy: 0.4748\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12086 training examples\n",
            "Loaded 3826 test examples\n",
            "Loaded 3021 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5204\n",
            "Final Validation Accuracy: 0.5230\n",
            "Final Test Accuracy: 0.4893\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12130 training examples\n",
            "Loaded 3771 test examples\n",
            "Loaded 3032 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5167\n",
            "Final Validation Accuracy: 0.5129\n",
            "Final Test Accuracy: 0.4909\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12086 training examples\n",
            "Loaded 3826 test examples\n",
            "Loaded 3021 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5256\n",
            "Final Validation Accuracy: 0.5081\n",
            "Final Test Accuracy: 0.5037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhDBWPHFup0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f47915c1-3fcd-490b-e509-310b6119327f"
      },
      "source": [
        "print(\"############ Fast Text #############\")\n",
        "print(\"############# Gender Text and Tweet Count, REMOVE Brand #################\")\n",
        "dataset_config = {\"dataset_type\" : DatasetEnum.GenderTextTweetCount, \"remove_brand\" : True }\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_fast_text(fast_text_config, dataset_config, text_process_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############ Fast Text #############\n",
            "############# Gender Text and Tweet Count, REMOVE Brand #################\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8310 training examples\n",
            "Loaded 2604 test examples\n",
            "Loaded 2077 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5243\n",
            "Final Validation Accuracy: 0.4949\n",
            "Final Test Accuracy: 0.5031\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8322 training examples\n",
            "Loaded 2588 test examples\n",
            "Loaded 2081 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5198\n",
            "Final Validation Accuracy: 0.5108\n",
            "Final Test Accuracy: 0.5062\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8295 training examples\n",
            "Loaded 2622 test examples\n",
            "Loaded 2074 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5169\n",
            "Final Validation Accuracy: 0.5174\n",
            "Final Test Accuracy: 0.5099\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8277 training examples\n",
            "Loaded 2645 test examples\n",
            "Loaded 2069 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5173\n",
            "Final Validation Accuracy: 0.5196\n",
            "Final Test Accuracy: 0.5078\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8322 training examples\n",
            "Loaded 2589 test examples\n",
            "Loaded 2080 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5154\n",
            "Final Validation Accuracy: 0.5240\n",
            "Final Test Accuracy: 0.5087\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8315 training examples\n",
            "Loaded 2597 test examples\n",
            "Loaded 2079 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5130\n",
            "Final Validation Accuracy: 0.5195\n",
            "Final Test Accuracy: 0.5214\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8305 training examples\n",
            "Loaded 2610 test examples\n",
            "Loaded 2076 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5951\n",
            "Final Validation Accuracy: 0.5934\n",
            "Final Test Accuracy: 0.5966\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 8296 training examples\n",
            "Loaded 2621 test examples\n",
            "Loaded 2074 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5141\n",
            "Final Validation Accuracy: 0.5188\n",
            "Final Test Accuracy: 0.5185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNiw367ZurhE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7102cf7-ea55-4a83-c6d6-5bd219c22efc"
      },
      "source": [
        "print(\"############### Fast Text ##################\")\n",
        "print(\"############## Gender Text and Tweet Count, KEEP Brand ############\")\n",
        "dataset_config = {\"dataset_type\" : DatasetEnum.GenderTextTweetCount, \"remove_brand\" : False }\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_fast_text(fast_text_config, dataset_config, text_process_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "############### Fast Text ##################\n",
            "############## Gender Text and Tweet Count, KEEP Brand ############\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12118 training examples\n",
            "Loaded 3785 test examples\n",
            "Loaded 3030 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5156\n",
            "Final Validation Accuracy: 0.5172\n",
            "Final Test Accuracy: 0.4787\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12115 training examples\n",
            "Loaded 3789 test examples\n",
            "Loaded 3029 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5238\n",
            "Final Validation Accuracy: 0.4982\n",
            "Final Test Accuracy: 0.5044\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12134 training examples\n",
            "Loaded 3766 test examples\n",
            "Loaded 3033 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5196\n",
            "Final Validation Accuracy: 0.4985\n",
            "Final Test Accuracy: 0.4750\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12092 training examples\n",
            "Loaded 3818 test examples\n",
            "Loaded 3023 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5205\n",
            "Final Validation Accuracy: 0.5018\n",
            "Final Test Accuracy: 0.5084\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12160 training examples\n",
            "Loaded 3733 test examples\n",
            "Loaded 3040 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5244\n",
            "Final Validation Accuracy: 0.5141\n",
            "Final Test Accuracy: 0.4715\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12134 training examples\n",
            "Loaded 3766 test examples\n",
            "Loaded 3033 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.4865\n",
            "Final Validation Accuracy: 0.4576\n",
            "Final Test Accuracy: 0.4700\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12172 training examples\n",
            "Loaded 3718 test examples\n",
            "Loaded 3043 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5256\n",
            "Final Validation Accuracy: 0.4942\n",
            "Final Test Accuracy: 0.4739\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "building vocab\n",
            "Loaded 12170 training examples\n",
            "Loaded 3721 test examples\n",
            "Loaded 3042 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.4849\n",
            "Final Validation Accuracy: 0.4803\n",
            "Final Test Accuracy: 0.4655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3W9GQqp5Wzq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hr9Q6rL5YZh"
      },
      "source": [
        "## Seq2Seq Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l077dM6xGi1m"
      },
      "source": [
        "class SeqToSeqConfig(object):\n",
        "    embed_size = 300\n",
        "    hidden_layers = 1\n",
        "    hidden_size = 32\n",
        "    bidirectional = True\n",
        "    output_size = 4\n",
        "    max_epochs = 15\n",
        "    lr = 0.5\n",
        "    batch_size = 128\n",
        "    dropout_keep = 0.8\n",
        "    max_sen_len = None # Sequence length for RNN\n",
        "\n",
        "class SeqToSeqDataset(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.train_iterator = None\n",
        "        self.test_iterator = None\n",
        "        self.val_iterator = None\n",
        "        self.vocab = []\n",
        "        self.word_embeddings = {}\n",
        "      \n",
        "    def load_data(self, w2v_file, train_test_file, dataset_config, text_process_args):       \n",
        "        NLP = spacy.load('en')\n",
        "        tokenizer = lambda sent: [x.text for x in NLP.tokenizer(sent) if x.text != \" \"]\n",
        "        \n",
        "        datafields, TEXT, LABEL, DESCRIPTION, TWEET_COUNT = get_datafields(dataset_config[\"dataset_type\"], tokenizer)            \n",
        "        train_data, test_data, val_data = get_train_test_val(train_test_file, datafields, dataset_config[\"dataset_type\"], text_process_args, remove_brand = dataset_config[\"remove_brand\"])\n",
        "                        \n",
        "        TEXT.build_vocab(train_data, vectors=Vectors(w2v_file))\n",
        "        \n",
        "        if dataset_config[\"dataset_type\"] == DatasetEnum.GenderTextDescription or dataset_config[\"dataset_type\"] == DatasetEnum.GenderTextDescriptionTweetCount:\n",
        "          DESCRIPTION.vocab = TEXT.vocab\n",
        "          \n",
        "        self.word_embeddings = TEXT.vocab.vectors\n",
        "        self.vocab = TEXT.vocab\n",
        "        \n",
        "        self.train_iterator = data.BucketIterator(\n",
        "            (train_data),\n",
        "            batch_size=self.config.batch_size,\n",
        "            sort_key=lambda x: len(x.text),\n",
        "            repeat=False,\n",
        "            shuffle=True)\n",
        "        \n",
        "        self.val_iterator, self.test_iterator = data.BucketIterator.splits(\n",
        "            (val_data, test_data),\n",
        "            batch_size=self.config.batch_size,\n",
        "            sort_key=lambda x: len(x.text),\n",
        "            repeat=False,\n",
        "            shuffle=False)\n",
        "        \n",
        "        if DEBUG:\n",
        "            print (\"Loaded {} training examples\".format(len(train_data)))\n",
        "            print (\"Loaded {} test examples\".format(len(test_data)))\n",
        "            print (\"Loaded {} validation examples\".format(len(val_data)))\n",
        "        \n",
        "        \n",
        "class Seq2SeqAttention(nn.Module):\n",
        "    def __init__(self, config, vocab_size, word_embeddings):\n",
        "        super(Seq2SeqAttention, self).__init__()\n",
        "        self.config = config\n",
        "        \n",
        "        # Embedding Layer\n",
        "        self.embeddings = nn.Embedding(vocab_size, self.config.embed_size)\n",
        "        self.embeddings.weight = nn.Parameter(word_embeddings, requires_grad=False)\n",
        "        \n",
        "        # Encoder RNN\n",
        "        self.lstm = nn.LSTM(input_size = self.config.embed_size,\n",
        "                            hidden_size = self.config.hidden_size,\n",
        "                            num_layers = self.config.hidden_layers,\n",
        "                            bidirectional = self.config.bidirectional)\n",
        "        \n",
        "        # Dropout Layer\n",
        "        self.dropout = nn.Dropout(self.config.dropout_keep)\n",
        "        \n",
        "        # Fully-Connected Layer\n",
        "        self.fc = nn.Linear(\n",
        "            self.config.hidden_size * (1+self.config.bidirectional) * 2,\n",
        "            self.config.output_size\n",
        "        )\n",
        "        \n",
        "        # Softmax non-linearity\n",
        "        self.softmax = nn.Softmax()\n",
        "                \n",
        "    def apply_attention(self, rnn_output, final_hidden_state):\n",
        "        '''\n",
        "        Apply Attention on RNN output\n",
        "        \n",
        "        Input:\n",
        "            rnn_output (batch_size, seq_len, num_directions * hidden_size): tensor representing hidden state for every word in the sentence\n",
        "            final_hidden_state (batch_size, num_directions * hidden_size): final hidden state of the RNN\n",
        "            \n",
        "        Returns:\n",
        "            attention_output(batch_size, num_directions * hidden_size): attention output vector for the batch\n",
        "        '''\n",
        "        hidden_state = final_hidden_state.unsqueeze(2)\n",
        "        attention_scores = torch.bmm(rnn_output, hidden_state).squeeze(2)\n",
        "        soft_attention_weights = F.softmax(attention_scores, 1).unsqueeze(2) #shape = (batch_size, seq_len, 1)\n",
        "        attention_output = torch.bmm(rnn_output.permute(0,2,1), soft_attention_weights).squeeze(2)\n",
        "        return attention_output\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x.shape = (max_sen_len, batch_size)\n",
        "        embedded_sent = self.embeddings(x)\n",
        "        # embedded_sent.shape = (max_sen_len=20, batch_size=64,embed_size=300)\n",
        "\n",
        "        ##################################### Encoder #######################################\n",
        "        lstm_output, (h_n,c_n) = self.lstm(embedded_sent)\n",
        "        # lstm_output.shape = (seq_len, batch_size, num_directions * hidden_size)\n",
        "        \n",
        "        # Final hidden state of last layer (num_directions, batch_size, hidden_size)\n",
        "        batch_size = h_n.shape[1]\n",
        "        h_n_final_layer = h_n.view(self.config.hidden_layers,\n",
        "                                   self.config.bidirectional + 1,\n",
        "                                   batch_size,\n",
        "                                   self.config.hidden_size)[-1,:,:,:]\n",
        "        \n",
        "        ##################################### Attention #####################################\n",
        "        # Convert input to (batch_size, num_directions * hidden_size) for attention\n",
        "        final_hidden_state = torch.cat([h_n_final_layer[i,:,:] for i in range(h_n_final_layer.shape[0])], dim=1)\n",
        "        \n",
        "        attention_out = self.apply_attention(lstm_output.permute(1,0,2), final_hidden_state)\n",
        "        # Attention_out.shape = (batch_size, num_directions * hidden_size)\n",
        "        \n",
        "        #################################### Linear #########################################\n",
        "        concatenated_vector = torch.cat([final_hidden_state, attention_out], dim=1)\n",
        "        final_feature_map = self.dropout(concatenated_vector) # shape=(batch_size, num_directions * hidden_size)\n",
        "        final_out = self.fc(final_feature_map)\n",
        "        return self.softmax(final_out)\n",
        "    \n",
        "    def add_optimizer(self, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "    def add_loss_op(self, loss_op):\n",
        "        self.loss_op = loss_op\n",
        "    \n",
        "    def reduce_lr(self):\n",
        "        if DEBUG:\n",
        "          print(\"Reducing LR\")\n",
        "        for g in self.optimizer.param_groups:\n",
        "            g['lr'] = g['lr'] / 2\n",
        "                \n",
        "    def run_epoch(self, train_iterator, val_iterator, epoch):\n",
        "        train_losses = []\n",
        "        val_accuracies = []\n",
        "        losses = []\n",
        "        \n",
        "        # Reduce learning rate as number of epochs increase\n",
        "        if (epoch == int(self.config.max_epochs/3)) or (epoch == int(2*self.config.max_epochs/3)):\n",
        "            self.reduce_lr()\n",
        "            \n",
        "        for i, batch in enumerate(train_iterator):\n",
        "            self.optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "                x = batch.text.cuda()\n",
        "                y = (batch.label - 1).type(torch.cuda.LongTensor)\n",
        "            else:\n",
        "                x = batch.text\n",
        "                y = (batch.label - 1).type(torch.LongTensor)\n",
        "            y_pred = self.__call__(x)\n",
        "            loss = self.loss_op(y_pred, y)\n",
        "            loss.backward()\n",
        "            losses.append(loss.data.cpu().numpy())\n",
        "            self.optimizer.step()\n",
        "    \n",
        "            if i % 100 == 0:\n",
        "                if DEBUG:\n",
        "                  print(\"Iter: {}\".format(i+1))\n",
        "                avg_train_loss = np.mean(losses)\n",
        "                train_losses.append(avg_train_loss)\n",
        "                if DEBUG:\n",
        "                  print(\"\\tAverage training loss: {:.5f}\".format(avg_train_loss))\n",
        "                losses = []\n",
        "                \n",
        "                # Evalute Accuracy on validation set\n",
        "                val_accuracy = evaluate_model(self, val_iterator)\n",
        "                if DEBUG:\n",
        "                  print(\"\\tVal Accuracy: {:.4f}\".format(val_accuracy))\n",
        "                self.train()\n",
        "                \n",
        "        return train_losses, val_accuracies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqbqTPmo57nb"
      },
      "source": [
        "### Running Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ggvp8EeN5gm"
      },
      "source": [
        "\n",
        "##### Seq2Seq ######\n",
        "def run_seq_to_seq(config, dataset_config, text_process_args):\n",
        "  print(\"################\")\n",
        "  print(text_process_args)\n",
        "  print(\"################\")\n",
        "  dataset = SeqToSeqDataset(config)\n",
        "  dataset.load_data(w2v_file, train_test_file, dataset_config, text_process_args)\n",
        "  model = Seq2SeqAttention(config, len(dataset.vocab), dataset.word_embeddings)\n",
        "  train_and_eval(model, config, dataset)\n",
        "  \n",
        "seq_to_seq_config = SeqToSeqConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8_D3HD_G8D1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aec10366-8435-459c-ff0d-1da15a562ae3"
      },
      "source": [
        "#### Seq2Seq TRAIN ######\n",
        "print(\"##### Seq2Seq ####\")\n",
        "dataset_config = dataset_configs[0]\n",
        "print(dataset_config)\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_seq_to_seq(seq_to_seq_config, dataset_config, text_process_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##### Seq2Seq ####\n",
            "{'dataset_type': <DatasetEnum.GenderText: 1>, 'remove_brand': True}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8339 training examples\n",
            "Loaded 2567 test examples\n",
            "Loaded 2085 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5107\n",
            "Final Validation Accuracy: 0.5194\n",
            "Final Test Accuracy: 0.5290\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8317 training examples\n",
            "Loaded 2595 test examples\n",
            "Loaded 2079 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5152\n",
            "Final Validation Accuracy: 0.5075\n",
            "Final Test Accuracy: 0.5241\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8382 training examples\n",
            "Loaded 2514 test examples\n",
            "Loaded 2095 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5156\n",
            "Final Validation Accuracy: 0.5222\n",
            "Final Test Accuracy: 0.5091\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8281 training examples\n",
            "Loaded 2640 test examples\n",
            "Loaded 2070 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5143\n",
            "Final Validation Accuracy: 0.5159\n",
            "Final Test Accuracy: 0.5193\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8386 training examples\n",
            "Loaded 2508 test examples\n",
            "Loaded 2097 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5186\n",
            "Final Validation Accuracy: 0.5274\n",
            "Final Test Accuracy: 0.4992\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8288 training examples\n",
            "Loaded 2631 test examples\n",
            "Loaded 2072 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5267\n",
            "Final Validation Accuracy: 0.5376\n",
            "Final Test Accuracy: 0.5310\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8316 training examples\n",
            "Loaded 2596 test examples\n",
            "Loaded 2079 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5189\n",
            "Final Validation Accuracy: 0.5204\n",
            "Final Test Accuracy: 0.5139\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8272 training examples\n",
            "Loaded 2651 test examples\n",
            "Loaded 2068 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5986\n",
            "Final Validation Accuracy: 0.5841\n",
            "Final Test Accuracy: 0.5681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8rcqwBdwtd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "07801145-56b9-45fa-8176-f3622b864a28"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "dataset_config = dataset_configs[1]\n",
        "print(dataset_config)\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_seq_to_seq(seq_to_seq_config, dataset_config, text_process_args)\n",
        "  \n",
        "print(\"----- seconds from start:\")\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset_type': <DatasetEnum.GenderText: 1>, 'remove_brand': False}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 12153 training examples\n",
            "Loaded 3742 test examples\n",
            "Loaded 3038 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:127: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5232\n",
            "Final Validation Accuracy: 0.5016\n",
            "Final Test Accuracy: 0.4832\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 12170 training examples\n",
            "Loaded 3720 test examples\n",
            "Loaded 3043 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5264\n",
            "Final Validation Accuracy: 0.4893\n",
            "Final Test Accuracy: 0.4898\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 12082 training examples\n",
            "Loaded 3831 test examples\n",
            "Loaded 3020 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5248\n",
            "Final Validation Accuracy: 0.5076\n",
            "Final Test Accuracy: 0.4931\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 12136 training examples\n",
            "Loaded 3763 test examples\n",
            "Loaded 3034 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5106\n",
            "Final Validation Accuracy: 0.5063\n",
            "Final Test Accuracy: 0.4858\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 12117 training examples\n",
            "Loaded 3787 test examples\n",
            "Loaded 3029 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5221\n",
            "Final Validation Accuracy: 0.5038\n",
            "Final Test Accuracy: 0.4753\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 12152 training examples\n",
            "Loaded 3743 test examples\n",
            "Loaded 3038 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5469\n",
            "Final Validation Accuracy: 0.5230\n",
            "Final Test Accuracy: 0.5330\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 12092 training examples\n",
            "Loaded 3818 test examples\n",
            "Loaded 3023 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5215\n",
            "Final Validation Accuracy: 0.5184\n",
            "Final Test Accuracy: 0.4966\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 12110 training examples\n",
            "Loaded 3796 test examples\n",
            "Loaded 3027 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5468\n",
            "Final Validation Accuracy: 0.5514\n",
            "Final Test Accuracy: 0.5443\n",
            "----- seconds from start:\n",
            "1431.969108581543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED871czYyGwx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19c8872c-4700-4cd3-e270-0630f33807d2"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "dataset_config = dataset_configs[2]\n",
        "print(dataset_config)\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_seq_to_seq(seq_to_seq_config, dataset_config, text_process_args)\n",
        "  \n",
        "print(\"----- seconds from start:\")\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset_type': <DatasetEnum.GenderTextDescription: 2>, 'remove_brand': True}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8338 training examples\n",
            "Loaded 2568 test examples\n",
            "Loaded 2085 validation examples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:127: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5169\n",
            "Final Validation Accuracy: 0.5026\n",
            "Final Test Accuracy: 0.5226\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8354 training examples\n",
            "Loaded 2549 test examples\n",
            "Loaded 2088 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5177\n",
            "Final Validation Accuracy: 0.5077\n",
            "Final Test Accuracy: 0.5155\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8362 training examples\n",
            "Loaded 2539 test examples\n",
            "Loaded 2090 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5175\n",
            "Final Validation Accuracy: 0.5148\n",
            "Final Test Accuracy: 0.5096\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8270 training examples\n",
            "Loaded 2653 test examples\n",
            "Loaded 2068 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5184\n",
            "Final Validation Accuracy: 0.5048\n",
            "Final Test Accuracy: 0.5153\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8216 training examples\n",
            "Loaded 2721 test examples\n",
            "Loaded 2054 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5175\n",
            "Final Validation Accuracy: 0.5190\n",
            "Final Test Accuracy: 0.5079\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8294 training examples\n",
            "Loaded 2623 test examples\n",
            "Loaded 2074 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5776\n",
            "Final Validation Accuracy: 0.5781\n",
            "Final Test Accuracy: 0.5703\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8306 training examples\n",
            "Loaded 2608 test examples\n",
            "Loaded 2077 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5200\n",
            "Final Validation Accuracy: 0.5060\n",
            "Final Test Accuracy: 0.5107\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Loaded 8261 training examples\n",
            "Loaded 2665 test examples\n",
            "Loaded 2065 validation examples\n",
            "Reducing LR\n",
            "Reducing LR\n",
            "Final Training Accuracy: 0.5757\n",
            "Final Validation Accuracy: 0.5758\n",
            "Final Test Accuracy: 0.5647\n",
            "----- seconds from start:\n",
            "1102.6336681842804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKGMevn2yJzm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64ba180b-3d7a-478c-9afa-6b80bc214ecc"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "dataset_config = dataset_configs[3]\n",
        "print(dataset_config)\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_seq_to_seq(seq_to_seq_config, dataset_config, text_process_args)\n",
        "  \n",
        "print(\"----- seconds from start:\")\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- start time:\n",
            "1569160291.9895594\n",
            "{'dataset_type': <DatasetEnum.GenderTextDescription: 2>, 'remove_brand': False}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:128: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.5223\n",
            "Final Validation Accuracy: 0.4972\n",
            "Final Test Accuracy: 0.4936\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.3541\n",
            "Final Validation Accuracy: 0.3588\n",
            "Final Test Accuracy: 0.3520\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5209\n",
            "Final Validation Accuracy: 0.5184\n",
            "Final Test Accuracy: 0.4833\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5217\n",
            "Final Validation Accuracy: 0.5068\n",
            "Final Test Accuracy: 0.5012\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5147\n",
            "Final Validation Accuracy: 0.4959\n",
            "Final Test Accuracy: 0.4914\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5449\n",
            "Final Validation Accuracy: 0.5139\n",
            "Final Test Accuracy: 0.5506\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5131\n",
            "Final Validation Accuracy: 0.5145\n",
            "Final Test Accuracy: 0.5061\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5496\n",
            "Final Validation Accuracy: 0.5352\n",
            "Final Test Accuracy: 0.5388\n",
            "----- seconds from start:\n",
            "1504.289431810379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2V_kHSpyNhv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66942f1e-05c2-4586-b32b-b1c42b5c3b9c"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "dataset_config = dataset_configs[4]\n",
        "print(dataset_config)\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_seq_to_seq(seq_to_seq_config, dataset_config, text_process_args)\n",
        "  \n",
        "print(\"----- seconds from start:\")\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset_type': <DatasetEnum.GenderTextDescriptionTweetCount: 3>, 'remove_brand': True}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:128: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.5168\n",
            "Final Validation Accuracy: 0.5246\n",
            "Final Test Accuracy: 0.5042\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5249\n",
            "Final Validation Accuracy: 0.5413\n",
            "Final Test Accuracy: 0.5234\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5127\n",
            "Final Validation Accuracy: 0.5192\n",
            "Final Test Accuracy: 0.5224\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5214\n",
            "Final Validation Accuracy: 0.5062\n",
            "Final Test Accuracy: 0.5069\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5990\n",
            "Final Validation Accuracy: 0.5947\n",
            "Final Test Accuracy: 0.5963\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5398\n",
            "Final Validation Accuracy: 0.5323\n",
            "Final Test Accuracy: 0.5319\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5193\n",
            "Final Validation Accuracy: 0.5144\n",
            "Final Test Accuracy: 0.5054\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5619\n",
            "Final Validation Accuracy: 0.5614\n",
            "Final Test Accuracy: 0.5646\n",
            "----- seconds from start:\n",
            "1057.8814771175385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTa6W49nyRlr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff8f8858-9618-4509-eacf-eefedadf108d"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "dataset_config = dataset_configs[5]\n",
        "print(dataset_config)\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_seq_to_seq(seq_to_seq_config, dataset_config, text_process_args)\n",
        "  \n",
        "print(\"----- seconds from start:\")\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset_type': <DatasetEnum.GenderTextTweetCount: 4>, 'remove_brand': True}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:128: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.5307\n",
            "Final Validation Accuracy: 0.5460\n",
            "Final Test Accuracy: 0.5474\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5160\n",
            "Final Validation Accuracy: 0.5234\n",
            "Final Test Accuracy: 0.5093\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5136\n",
            "Final Validation Accuracy: 0.5131\n",
            "Final Test Accuracy: 0.5316\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5377\n",
            "Final Validation Accuracy: 0.5493\n",
            "Final Test Accuracy: 0.5307\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5122\n",
            "Final Validation Accuracy: 0.5300\n",
            "Final Test Accuracy: 0.5296\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5995\n",
            "Final Validation Accuracy: 0.6279\n",
            "Final Test Accuracy: 0.6001\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5182\n",
            "Final Validation Accuracy: 0.5115\n",
            "Final Test Accuracy: 0.5113\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5933\n",
            "Final Validation Accuracy: 0.5899\n",
            "Final Test Accuracy: 0.5850\n",
            "----- seconds from start:\n",
            "1016.6757659912109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QDfSskxyaL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e240e6d-00a0-41ab-fdc1-a321570e82e0"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "dataset_config = dataset_configs[6]\n",
        "print(dataset_config)\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_seq_to_seq(seq_to_seq_config, dataset_config, text_process_args)\n",
        "  \n",
        "print(\"----- seconds from start:\")\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset_type': <DatasetEnum.GenderTextTweetCount: 4>, 'remove_brand': False}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:128: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.5124\n",
            "Final Validation Accuracy: 0.5218\n",
            "Final Test Accuracy: 0.4959\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5221\n",
            "Final Validation Accuracy: 0.5241\n",
            "Final Test Accuracy: 0.4984\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5254\n",
            "Final Validation Accuracy: 0.5015\n",
            "Final Test Accuracy: 0.4918\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.3534\n",
            "Final Validation Accuracy: 0.3569\n",
            "Final Test Accuracy: 0.3648\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5118\n",
            "Final Validation Accuracy: 0.5060\n",
            "Final Test Accuracy: 0.4610\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5470\n",
            "Final Validation Accuracy: 0.5308\n",
            "Final Test Accuracy: 0.5327\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5206\n",
            "Final Validation Accuracy: 0.5021\n",
            "Final Test Accuracy: 0.4887\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5459\n",
            "Final Validation Accuracy: 0.5409\n",
            "Final Test Accuracy: 0.5295\n",
            "----- seconds from start:\n",
            "1435.8302347660065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b3UQvuPyRp8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2f45ec0-2a69-4b26-aaa7-d36193186f96"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "dataset_config = dataset_configs[7]\n",
        "print(dataset_config)\n",
        "\n",
        "for text_process_args in text_process_args_vars: \n",
        "  run_seq_to_seq(seq_to_seq_config, dataset_config, text_process_args)\n",
        "  \n",
        "print(\"----- seconds from start:\")\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset_type': <DatasetEnum.GenderTextDescriptionTweetCount: 3>, 'remove_brand': False}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:128: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.5255\n",
            "Final Validation Accuracy: 0.5115\n",
            "Final Test Accuracy: 0.4684\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5150\n",
            "Final Validation Accuracy: 0.5126\n",
            "Final Test Accuracy: 0.5127\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5249\n",
            "Final Validation Accuracy: 0.5010\n",
            "Final Test Accuracy: 0.4596\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5130\n",
            "Final Validation Accuracy: 0.5117\n",
            "Final Test Accuracy: 0.4989\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5248\n",
            "Final Validation Accuracy: 0.5039\n",
            "Final Test Accuracy: 0.4603\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5548\n",
            "Final Validation Accuracy: 0.5298\n",
            "Final Test Accuracy: 0.5208\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5200\n",
            "Final Validation Accuracy: 0.5102\n",
            "Final Test Accuracy: 0.4589\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5471\n",
            "Final Validation Accuracy: 0.5388\n",
            "Final Test Accuracy: 0.5378\n",
            "----- seconds from start:\n",
            "1499.8615946769714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vx59b0v4cmf"
      },
      "source": [
        "## Text RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U08tVdoscS6"
      },
      "source": [
        "class TextRNNConfig(object):\n",
        "    embed_size = 300\n",
        "    hidden_layers = 2\n",
        "    hidden_size = 32\n",
        "    bidirectional = True\n",
        "    output_size = 4\n",
        "    max_epochs = 10\n",
        "    lr = 0.25\n",
        "    batch_size = 64\n",
        "    max_sen_len = 20 # Sequence length for RNN\n",
        "    dropout_keep = 0.8\n",
        "    \n",
        "class TextRNN(nn.Module):\n",
        "    def __init__(self, config, vocab_size, word_embeddings):\n",
        "        super(TextRNN, self).__init__()\n",
        "        self.config = config\n",
        "        \n",
        "        # Embedding Layer\n",
        "        self.embeddings = nn.Embedding(vocab_size, self.config.embed_size)\n",
        "        self.embeddings.weight = nn.Parameter(word_embeddings, requires_grad=False)\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size = self.config.embed_size,\n",
        "                            hidden_size = self.config.hidden_size,\n",
        "                            num_layers = self.config.hidden_layers,\n",
        "                            dropout = self.config.dropout_keep,\n",
        "                            bidirectional = self.config.bidirectional)\n",
        "        \n",
        "        self.dropout = nn.Dropout(self.config.dropout_keep)\n",
        "        \n",
        "        # Fully-Connected Layer\n",
        "        self.fc = nn.Linear(\n",
        "            self.config.hidden_size * self.config.hidden_layers * (1+self.config.bidirectional),\n",
        "            self.config.output_size\n",
        "        )\n",
        "        \n",
        "        # Softmax non-linearity\n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x.shape = (max_sen_len, batch_size)\n",
        "        embedded_sent = self.embeddings(x)\n",
        "        # embedded_sent.shape = (max_sen_len=20, batch_size=64,embed_size=300)\n",
        "\n",
        "        lstm_out, (h_n,c_n) = self.lstm(embedded_sent)\n",
        "        final_feature_map = self.dropout(h_n) # shape=(num_layers * num_directions, 64, hidden_size)\n",
        "        \n",
        "        # Convert input to (64, hidden_size * hidden_layers * num_directions) for linear layer\n",
        "        final_feature_map = torch.cat([final_feature_map[i,:,:] for i in range(final_feature_map.shape[0])], dim=1)\n",
        "        final_out = self.fc(final_feature_map)\n",
        "        return self.softmax(final_out)\n",
        "    \n",
        "    def add_optimizer(self, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "    def add_loss_op(self, loss_op):\n",
        "        self.loss_op = loss_op\n",
        "    \n",
        "    def reduce_lr(self):\n",
        "        if DEBUG:\n",
        "          print(\"Reducing LR\")\n",
        "        for g in self.optimizer.param_groups:\n",
        "            g['lr'] = g['lr'] / 2\n",
        "                \n",
        "    def run_epoch(self, train_iterator, val_iterator, epoch):\n",
        "        train_losses = []\n",
        "        val_accuracies = []\n",
        "        losses = []\n",
        "        \n",
        "        # Reduce learning rate as number of epochs increase\n",
        "        if (epoch == int(self.config.max_epochs/3)) or (epoch == int(2*self.config.max_epochs/3)):\n",
        "            self.reduce_lr()\n",
        "            \n",
        "        for i, batch in enumerate(train_iterator):\n",
        "            self.optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "                x = batch.text.cuda()\n",
        "                y = (batch.label - 1).type(torch.cuda.LongTensor)\n",
        "            else:\n",
        "                x = batch.text\n",
        "                y = (batch.label - 1).type(torch.LongTensor)\n",
        "            y_pred = self.__call__(x)\n",
        "            loss = self.loss_op(y_pred, y)\n",
        "            loss.backward()\n",
        "            losses.append(loss.data.cpu().numpy())\n",
        "            self.optimizer.step()\n",
        "    \n",
        "            if i % 100 == 0:\n",
        "                if DEBUG:\n",
        "                  print(\"Iter: {}\".format(i+1))\n",
        "                avg_train_loss = np.mean(losses)\n",
        "                train_losses.append(avg_train_loss)\n",
        "                if DEBUG:\n",
        "                  print(\"\\tAverage training loss: {:.5f}\".format(avg_train_loss))\n",
        "                losses = []\n",
        "                \n",
        "                # Evalute Accuracy on validation set\n",
        "                val_accuracy = evaluate_model(self, val_iterator)\n",
        "                if DEBUG:\n",
        "                  print(\"\\tVal Accuracy: {:.4f}\".format(val_accuracy))\n",
        "                self.train()\n",
        "                \n",
        "        return train_losses, val_accuracies\n",
        "      \n",
        "class TextRNNDataset(object):\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.train_iterator = None\n",
        "        self.test_iterator = None\n",
        "        self.val_iterator = None\n",
        "        self.vocab = []\n",
        "        self.word_embeddings = {}       \n",
        "    \n",
        "    def load_data(self, w2v_file, train_test_file, dataset_config, text_process_args):       \n",
        "\n",
        "        NLP = spacy.load('en')\n",
        "        tokenizer = lambda sent: [x.text for x in NLP.tokenizer(sent) if x.text != \" \"]\n",
        "        \n",
        "        datafields, TEXT, LABEL, DESCRIPTION, TWEET_COUNT = get_datafields(dataset_config[\"dataset_type\"], tokenizer)            \n",
        "        train_data, test_data, val_data = get_train_test_val(train_test_file, datafields, dataset_config[\"dataset_type\"], text_process_args, remove_brand = dataset_config[\"remove_brand\"])\n",
        "        \n",
        "        \n",
        "        \n",
        "        TEXT.build_vocab(train_data, vectors=Vectors(w2v_file))\n",
        "        self.word_embeddings = TEXT.vocab.vectors\n",
        "        self.vocab = TEXT.vocab\n",
        "        \n",
        "        if dataset_config[\"dataset_type\"] == DatasetEnum.GenderTextDescription or dataset_config[\"dataset_type\"] == DatasetEnum.GenderTextDescriptionTweetCount:\n",
        "          DESCRIPTION.vocab = TEXT.vocab\n",
        "          \n",
        "        self.train_iterator = data.BucketIterator(\n",
        "            (train_data),\n",
        "            batch_size=self.config.batch_size,\n",
        "            sort_key=lambda x: len(x.text),\n",
        "            repeat=False,\n",
        "            shuffle=True)\n",
        "        \n",
        "        self.val_iterator, self.test_iterator = data.BucketIterator.splits(\n",
        "            (val_data, test_data),\n",
        "            batch_size=self.config.batch_size,\n",
        "            sort_key=lambda x: len(x.text),\n",
        "            repeat=False,\n",
        "            shuffle=False)\n",
        "        if DEBUG:\n",
        "          print (\"Loaded {} training examples\".format(len(train_data)))\n",
        "          print (\"Loaded {} test examples\".format(len(test_data)))\n",
        "          print (\"Loaded {} validation examples\".format(len(val_data)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZSX23hV4h8l"
      },
      "source": [
        "### Running Text RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE3t58WFV3wp"
      },
      "source": [
        "##### TEXT RNN ######\n",
        "def run_text_rnn(config, dataset_config, text_process_args):\n",
        "  print(\"################\")\n",
        "  print(text_process_args)\n",
        "  print(\"################\")\n",
        "  dataset = TextRNNDataset(config)\n",
        "  dataset.load_data(w2v_file, train_test_file, dataset_config, text_process_args)\n",
        "  model = TextRNN(config, len(dataset.vocab), dataset.word_embeddings)\n",
        "  train_and_eval(model, config, dataset)\n",
        "  \n",
        "text_rnn_config = TextRNNConfig()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54dpLvUPWwEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "afd70a33-5a57-4081-e4a4-0eccb948e7d5"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "for dataset_config in dataset_configs:\n",
        "  print(dataset_config)\n",
        "\n",
        "  for text_process_args in text_process_args_vars: \n",
        "    run_text_rnn(text_rnn_config, dataset_config, text_process_args)\n",
        "  print(\"----- seconds from start:\")\n",
        "  end = time.time()\n",
        "  print(end - start)\n",
        "\n",
        "print(\"----- TOTAL seconds from start:\")\n",
        "end = time.time()\n",
        "print(end - start)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset_type': <DatasetEnum.GenderText: 1>, 'remove_brand': True}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 2195899/2196018 [05:31<00:00, 7823.64it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.5228\n",
            "Final Validation Accuracy: 0.4976\n",
            "Final Test Accuracy: 0.5076\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5635\n",
            "Final Validation Accuracy: 0.5607\n",
            "Final Test Accuracy: 0.5565\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5201\n",
            "Final Validation Accuracy: 0.4966\n",
            "Final Test Accuracy: 0.5172\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5151\n",
            "Final Validation Accuracy: 0.5378\n",
            "Final Test Accuracy: 0.5141\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5184\n",
            "Final Validation Accuracy: 0.5366\n",
            "Final Test Accuracy: 0.5391\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5521\n",
            "Final Validation Accuracy: 0.5653\n",
            "Final Test Accuracy: 0.5761\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5174\n",
            "Final Validation Accuracy: 0.5153\n",
            "Final Test Accuracy: 0.5106\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5573\n",
            "Final Validation Accuracy: 0.5711\n",
            "Final Test Accuracy: 0.5641\n",
            "----- seconds from start:\n",
            "1944.0557856559753\n",
            "{'dataset_type': <DatasetEnum.GenderText: 1>, 'remove_brand': False}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5180\n",
            "Final Validation Accuracy: 0.4928\n",
            "Final Test Accuracy: 0.4815\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.3541\n",
            "Final Validation Accuracy: 0.3454\n",
            "Final Test Accuracy: 0.3648\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5195\n",
            "Final Validation Accuracy: 0.5002\n",
            "Final Test Accuracy: 0.4758\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5164\n",
            "Final Validation Accuracy: 0.5119\n",
            "Final Test Accuracy: 0.4961\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5095\n",
            "Final Validation Accuracy: 0.5081\n",
            "Final Test Accuracy: 0.4906\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5378\n",
            "Final Validation Accuracy: 0.5345\n",
            "Final Test Accuracy: 0.5261\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5185\n",
            "Final Validation Accuracy: 0.4983\n",
            "Final Test Accuracy: 0.4845\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5287\n",
            "Final Validation Accuracy: 0.5244\n",
            "Final Test Accuracy: 0.5164\n",
            "----- seconds from start:\n",
            "4015.683585882187\n",
            "{'dataset_type': <DatasetEnum.GenderTextDescription: 2>, 'remove_brand': True}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5111\n",
            "Final Validation Accuracy: 0.5314\n",
            "Final Test Accuracy: 0.5184\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5145\n",
            "Final Validation Accuracy: 0.5268\n",
            "Final Test Accuracy: 0.5147\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5153\n",
            "Final Validation Accuracy: 0.5212\n",
            "Final Test Accuracy: 0.5128\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5225\n",
            "Final Validation Accuracy: 0.4896\n",
            "Final Test Accuracy: 0.5146\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5130\n",
            "Final Validation Accuracy: 0.5140\n",
            "Final Test Accuracy: 0.5296\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5519\n",
            "Final Validation Accuracy: 0.5594\n",
            "Final Test Accuracy: 0.5494\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5181\n",
            "Final Validation Accuracy: 0.5294\n",
            "Final Test Accuracy: 0.4975\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5587\n",
            "Final Validation Accuracy: 0.5316\n",
            "Final Test Accuracy: 0.5639\n",
            "----- seconds from start:\n",
            "5405.26264166832\n",
            "{'dataset_type': <DatasetEnum.GenderTextDescription: 2>, 'remove_brand': False}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5117\n",
            "Final Validation Accuracy: 0.5104\n",
            "Final Test Accuracy: 0.4860\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5064\n",
            "Final Validation Accuracy: 0.4969\n",
            "Final Test Accuracy: 0.5190\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5187\n",
            "Final Validation Accuracy: 0.4962\n",
            "Final Test Accuracy: 0.4696\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5184\n",
            "Final Validation Accuracy: 0.5069\n",
            "Final Test Accuracy: 0.5042\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5162\n",
            "Final Validation Accuracy: 0.5055\n",
            "Final Test Accuracy: 0.4782\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5415\n",
            "Final Validation Accuracy: 0.5347\n",
            "Final Test Accuracy: 0.5297\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5116\n",
            "Final Validation Accuracy: 0.5290\n",
            "Final Test Accuracy: 0.4842\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5342\n",
            "Final Validation Accuracy: 0.5440\n",
            "Final Test Accuracy: 0.5287\n",
            "----- seconds from start:\n",
            "7444.356376409531\n",
            "{'dataset_type': <DatasetEnum.GenderTextDescriptionTweetCount: 3>, 'remove_brand': True}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5186\n",
            "Final Validation Accuracy: 0.4930\n",
            "Final Test Accuracy: 0.5248\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5136\n",
            "Final Validation Accuracy: 0.5137\n",
            "Final Test Accuracy: 0.5251\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5156\n",
            "Final Validation Accuracy: 0.5070\n",
            "Final Test Accuracy: 0.5231\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5106\n",
            "Final Validation Accuracy: 0.5472\n",
            "Final Test Accuracy: 0.5067\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5182\n",
            "Final Validation Accuracy: 0.5223\n",
            "Final Test Accuracy: 0.5027\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5648\n",
            "Final Validation Accuracy: 0.5623\n",
            "Final Test Accuracy: 0.5776\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5122\n",
            "Final Validation Accuracy: 0.5319\n",
            "Final Test Accuracy: 0.5136\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5605\n",
            "Final Validation Accuracy: 0.5603\n",
            "Final Test Accuracy: 0.5634\n",
            "----- seconds from start:\n",
            "8902.821792125702\n",
            "{'dataset_type': <DatasetEnum.GenderTextTweetCount: 4>, 'remove_brand': True}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5150\n",
            "Final Validation Accuracy: 0.5338\n",
            "Final Test Accuracy: 0.5044\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5144\n",
            "Final Validation Accuracy: 0.5174\n",
            "Final Test Accuracy: 0.5222\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5159\n",
            "Final Validation Accuracy: 0.5034\n",
            "Final Test Accuracy: 0.5256\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5111\n",
            "Final Validation Accuracy: 0.5152\n",
            "Final Test Accuracy: 0.5312\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5169\n",
            "Final Validation Accuracy: 0.5118\n",
            "Final Test Accuracy: 0.5155\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5605\n",
            "Final Validation Accuracy: 0.5504\n",
            "Final Test Accuracy: 0.5556\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5190\n",
            "Final Validation Accuracy: 0.5127\n",
            "Final Test Accuracy: 0.5075\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5586\n",
            "Final Validation Accuracy: 0.5539\n",
            "Final Test Accuracy: 0.5640\n",
            "----- seconds from start:\n",
            "10302.729561328888\n",
            "{'dataset_type': <DatasetEnum.GenderTextTweetCount: 4>, 'remove_brand': False}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5177\n",
            "Final Validation Accuracy: 0.4998\n",
            "Final Test Accuracy: 0.4680\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5118\n",
            "Final Validation Accuracy: 0.5245\n",
            "Final Test Accuracy: 0.5035\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5138\n",
            "Final Validation Accuracy: 0.5035\n",
            "Final Test Accuracy: 0.4659\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5154\n",
            "Final Validation Accuracy: 0.5015\n",
            "Final Test Accuracy: 0.5035\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5157\n",
            "Final Validation Accuracy: 0.4952\n",
            "Final Test Accuracy: 0.4922\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5235\n",
            "Final Validation Accuracy: 0.5132\n",
            "Final Test Accuracy: 0.4991\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5155\n",
            "Final Validation Accuracy: 0.5050\n",
            "Final Test Accuracy: 0.4641\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.4350\n",
            "Final Validation Accuracy: 0.4569\n",
            "Final Test Accuracy: 0.4578\n",
            "----- seconds from start:\n",
            "12275.25130558014\n",
            "{'dataset_type': <DatasetEnum.GenderTextDescriptionTweetCount: 3>, 'remove_brand': False}\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5162\n",
            "Final Validation Accuracy: 0.5016\n",
            "Final Test Accuracy: 0.4594\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5117\n",
            "Final Validation Accuracy: 0.5016\n",
            "Final Test Accuracy: 0.4897\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5247\n",
            "Final Validation Accuracy: 0.4987\n",
            "Final Test Accuracy: 0.4606\n",
            "################\n",
            "{'keep_letters_only': True, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5169\n",
            "Final Validation Accuracy: 0.5093\n",
            "Final Test Accuracy: 0.5148\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5204\n",
            "Final Validation Accuracy: 0.5012\n",
            "Final Test Accuracy: 0.4660\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': True, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5439\n",
            "Final Validation Accuracy: 0.5220\n",
            "Final Test Accuracy: 0.5351\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': True}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5213\n",
            "Final Validation Accuracy: 0.5003\n",
            "Final Test Accuracy: 0.4618\n",
            "################\n",
            "{'keep_letters_only': False, 'to_lower_case': True, 'lemmatize': False, 'remove_stopwords': False}\n",
            "################\n",
            "done loading data\n",
            "Final Training Accuracy: 0.5382\n",
            "Final Validation Accuracy: 0.5436\n",
            "Final Test Accuracy: 0.5292\n",
            "----- seconds from start:\n",
            "14372.665852308273\n",
            "----- TOTAL seconds from start:\n",
            "14372.666857719421\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}